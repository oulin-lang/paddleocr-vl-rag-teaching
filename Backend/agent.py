import os
import time
import json
import asyncio
from typing import List, Dict, Optional, AsyncIterator, Any
from tenacity import retry, stop_after_attempt, wait_fixed, stop_after_delay, retry_if_exception_type


try:
    from dotenv import load_dotenv
except ImportError:
    def load_dotenv():
        return None

from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.checkpoint.memory import InMemorySaver
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.runnables import RunnableLambda

from config import settings
from runtime_config import runtime_config

load_dotenv()


class Agent:
    """æ™ºèƒ½ä½“ç±» - ç»Ÿä¸€çš„é«˜è´¨é‡æ•™å¸ˆè¾…åŠ©æ™ºèƒ½ä½“"""

    def __init__(self, model_name: str = settings.model_name):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“

        Args:
            model_name: æ¨¡å‹åç§°
        """
        # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹
        self.llm = ChatOpenAI(
            api_key=os.getenv('ALIYUNBAILIAN_API_KEY'),
            base_url=settings.base_url,
            model=model_name,
            temperature=0.7,
            max_tokens=2000,
            streaming=True  # å¯ç”¨æµå¼
        )

        # å­˜å‚¨ä¼šè¯å†å²
        self.session_memory: Dict[str, List[Dict]] = {}
        # ä¼šè¯è®°å¿†å­˜å‚¨è·¯å¾„ï¼ŒæŒ‡å‘ Backend/storage/session_memory
        self.memory_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "storage", "session_memory")
        os.makedirs(self.memory_dir, exist_ok=True)

        # å·¥å…·åˆ—è¡¨å’ŒMCPå®¢æˆ·ç«¯
        self.tools = []
        self.agent = None          # å½“å‰ä½¿ç”¨çš„Agent
        self.agent_basic = None    # åŸºç¡€Agent (æ— å·¥å…·)
        self.agent_search = None   # æœç´¢Agent (æœ‰å·¥å…·)
        self.mcp_client = None
        self.checkpointer = InMemorySaver() # å…±äº«æ£€æŸ¥ç‚¹

        # æ ‡è®°åˆå§‹åŒ–çŠ¶æ€
        self._initialized = False

    async def _create_agent(self, tools: List[Any]):
        """
        åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        Args:
            tools: å·¥å…·åˆ—è¡¨
            
        Returns:
            åˆ›å»ºçš„æ™ºèƒ½ä½“å®ä¾‹
        """
        try:
            # ä½¿ç”¨LangChain 1.xçš„create_agentå‡½æ•°
            agent = create_agent(
                model=self.llm,
                tools=tools,
                system_prompt=settings.system_prompt,
                checkpointer=self.checkpointer,
            )
            return agent
        except Exception:
            return await self._create_fallback_agent() 
 
    async def _create_fallback_agent(self): 
        """ 
        åˆ›å»ºå›é€€åŸºç¡€æ™ºèƒ½ä½“ï¼ˆå¼‚æ­¥æ–¹æ³•ï¼‰ 
        
        Returns: 
            åŸºç¡€æ™ºèƒ½ä½“å®ä¾‹ 
        """ 
        from langchain_core.prompts import ChatPromptTemplate
        
        # ä½¿ç”¨PromptTemplate + LLMæ„å»ºç®€å•çš„Chainï¼Œæ”¯æŒæµå¼è¾“å‡º
        prompt = ChatPromptTemplate.from_messages([
            ("system", "{system_prompt}"),
            ("human", "{input}"),
        ])
        
        self.agent = prompt | self.llm
        return self.agent 
 
    async def chat(self, session_id: str, user_input: str, system_prompt: Optional[str] = None) -> str: 
        """ 
        ç»Ÿä¸€çš„èŠå¤©æ–¹æ³•ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰ 
 
        Args: 
            session_id: ä¼šè¯ID 
            user_input: ç”¨æˆ·è¾“å…¥ 
            system_prompt: ç³»ç»Ÿæç¤ºè¯ (å¯é€‰ï¼Œé€šå¸¸ä¸å†éœ€è¦ï¼Œä½¿ç”¨ç»Ÿä¸€Prompt) 
 
        Returns: 
            æ™ºèƒ½ä½“å“åº” 
        """ 
        try: 
            # ç¡®ä¿æ™ºèƒ½ä½“å·²åˆå§‹åŒ– 
            if not self._initialized: 
                await self._async_init() 
                self._initialized = True 
 
            # é»˜è®¤ä½¿ç”¨ç»Ÿä¸€é…ç½®çš„system_promptï¼Œé™¤éæ˜ç¡®è¦†ç›– 
            if system_prompt is None: 
                system_prompt = settings.system_prompt 
 
            # æ›´æ–°ä¼šè¯è®°å¿† 
            if session_id not in self.session_memory: 
                self.session_memory[session_id] = [] 
 
            self.session_memory[session_id].append({ 
                "role": "user", 
                "content": user_input, 
                "timestamp": time.time() 
            }) 
 
            # å‡†å¤‡è¾“å…¥æ•°æ® 
            input_data = { 
                "input": user_input, 
                "messages": [HumanMessage(content=user_input)], 
                "system_prompt": system_prompt 
            } 
 
            # é…ç½®å‚æ•°ï¼ˆåŒ…å«æ£€æŸ¥ç‚¹çº¿ç¨‹IDï¼‰ 
            config = { 
                "configurable": { 
                    "thread_id": session_id 
                } 
            } 

            # è°ƒç”¨æ™ºèƒ½ä½“ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰ 
            result = await self._async_chat(input_data, config) 
            if not result: 
                # å°è¯•åŒæ­¥è°ƒç”¨ 
                result = self.agent.invoke(input_data, config=config) if self.agent else None 

            # æå–å›å¤å†…å®¹ 
            response = self._extract_response(result) if result else "æœªæ”¶åˆ°å“åº”" 
 
            # ä¿å­˜åˆ°è®°å¿† 
            self.session_memory[session_id].append({ 
                "role": "assistant", 
                "content": response, 
                "timestamp": time.time() 
            }) 
 
            # ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶ 
            self._save_session(session_id) 
 
            return response 
 
        except Exception as e: 
            import traceback
            traceback.print_exc()
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}" 
            return error_msg 
 
    async def _async_chat(self, input_data: Dict, config: Dict): 
        """ 
        å¼‚æ­¥èŠå¤©æ–¹æ³• 
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            config: è¿è¡Œé…ç½®
            
        Returns:
            è°ƒç”¨ç»“æœ
        """ 
        if self.agent: 
            try: 
                # å°è¯•å¼‚æ­¥è°ƒç”¨ 
                if hasattr(self.agent, 'ainvoke'): 
                    result = await self.agent.ainvoke(input_data, config=config) 
                else: 
                    # é™çº§åˆ°åŒæ­¥è°ƒç”¨ 
                    result = self.agent.invoke(input_data, config=config) 
                return result 
            except Exception: 
                import traceback
                traceback.print_exc()
                return None 
        return None 
 
    def _extract_response(self, result) -> str: 
        """ 
        æå–æ™ºèƒ½ä½“å“åº” 
        
        Args:
            result: æ™ºèƒ½ä½“æ‰§è¡Œç»“æœ
            
        Returns:
            æå–çš„å›å¤å†…å®¹
        """ 
        response_content = ""
        if isinstance(result, dict): 
            # æ£€æŸ¥æ˜¯å¦æœ‰messageså­—æ®µ 
            if "messages" in result: 
                messages = result["messages"] 
                if messages: 
                    last_message = messages[-1] 
                    if hasattr(last_message, 'content'): 
                        response_content = last_message.content 
                    elif isinstance(last_message, dict): 
                        response_content = last_message.get("content", str(last_message)) 
            
            # æ£€æŸ¥æ˜¯å¦æœ‰outputå­—æ®µ (å¦‚æœmessagesæ²¡æ‰¾åˆ°æˆ–ä¸ºç©º)
            if not response_content and "output" in result: 
                output = result["output"] 
                if hasattr(output, 'content'): 
                    response_content = output.content 
                else: 
                    response_content = str(output) 
        else:
            # é»˜è®¤è¿”å›å­—ç¬¦ä¸²è¡¨ç¤º 
            response_content = str(result)
        
        # å¤„ç†å›å¤å†…å®¹ä¸­çš„æ ¼å¼é—®é¢˜
        if response_content:
            # æ›¿æ¢å­—é¢é‡çš„ "/n" ä¸ºæ¢è¡Œç¬¦ (é’ˆå¯¹ç”¨æˆ·åé¦ˆçš„é—®é¢˜)
            response_content = response_content.replace("/n", "\n")
            # æ›¿æ¢å¯èƒ½çš„è½¬ä¹‰æ¢è¡Œç¬¦ "\\n" ä¸º "\n"
            response_content = response_content.replace("\\n", "\n")
            
        return response_content 
 
    async def _async_init(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        # åŠ è½½å·¥å…·
        await self._load_tools_async()

        # åˆ›å»ºåŸºç¡€æ™ºèƒ½ä½“ (æ— å·¥å…·)
        self.agent_basic = await self._create_agent(tools=[])

        # åˆ›å»ºæœç´¢æ™ºèƒ½ä½“ (æœ‰å·¥å…·)
        if self.tools:
            self.agent_search = await self._create_agent(tools=self.tools)
        else:
            self.agent_search = self.agent_basic

        # é»˜è®¤ä½¿ç”¨åŸºç¡€æ™ºèƒ½ä½“
        self.agent = self.agent_basic
        self._initialized = True

    async def _load_tools_async(self):
        """å¼‚æ­¥åŠ è½½å·¥å…· (å¸¦é‡è¯•æœºåˆ¶)"""
        self.tools = []
        
        # 1. å°è¯•åŠ è½½ MCP å·¥å…·
        if runtime_config.enable_mcp_access and settings.mcp_servers:
            try:
                self.mcp_client = MultiServerMCPClient(settings.mcp_servers)
                mcp_tools = await self.mcp_client.get_tools()
                self.tools.extend(mcp_tools)
                print(f"[Agent] Successfully loaded {len(mcp_tools)} tools from MCP servers.")
            except Exception as e:
                print(f"[Agent] Failed to load MCP tools: {e}")
        
        # 2. å°è¯•åŠ è½½ Tavily æœç´¢å·¥å…· (ä½œä¸ºå¤‡ç”¨æˆ–è¡¥å……)
        if os.getenv("TAVILY_API_KEY"):
            try:
                # åŒ…è£… Tavily å·¥å…·ä»¥æ”¯æŒé‡è¯•
                tavily_tool = TavilySearchResults(max_results=5)
                
                # æš‚æ—¶ç§»é™¤ invoke çš„ monkey patchï¼Œå› ä¸ºå®ƒå¯¼è‡´äº† "object has no field 'invoke'" é”™è¯¯
                # å¦‚æœéœ€è¦é‡è¯•æœºåˆ¶ï¼Œåº”è¯¥ä½¿ç”¨ LangChain çš„ .with_retry() æ–¹æ³•æˆ–è€…å…¶ä»–æ ‡å‡†æ–¹å¼
                
                self.tools.append(tavily_tool)
                print("[Agent] Added TavilySearchResults tool.")
            except Exception as e:
                print(f"[Agent] Failed to add Tavily tool: {e}")
 
 
    async def should_search(self, user_input: str) -> bool:
        """
        åˆ¤æ–­ç”¨æˆ·é—®é¢˜æ˜¯å¦éœ€è¦è”ç½‘æœç´¢
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            True if search is needed, False otherwise
        """
        try:
            prompt = f"""
            è¯·åˆ¤æ–­ä»¥ä¸‹ç”¨æˆ·é—®é¢˜æ˜¯å¦éœ€è¦å®æ—¶è”ç½‘æœç´¢æ‰èƒ½å›ç­”ã€‚
            å¦‚æœæ˜¯å…³äºæ—¶äº‹æ–°é—»ã€å¤©æ°”ã€æœ€æ–°æŠ€æœ¯åŠ¨æ€ã€ç‰¹å®šå…·ä½“æ•°æ®ç­‰éœ€è¦å¤–éƒ¨ä¿¡æ¯çš„é—®é¢˜ï¼Œè¿”å› "YES"ã€‚
            å¦‚æœæ˜¯é€šç”¨çŸ¥è¯†ã€é€»è¾‘æ¨ç†ã€é—²èŠæˆ–å·²æœ‰ä¸Šä¸‹æ–‡çš„é—®é¢˜ï¼Œè¿”å› "NO"ã€‚
            
            é—®é¢˜: {user_input}
            
            åªè¿”å› YES æˆ– NOï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
            """
            messages = [HumanMessage(content=prompt)]
            response = await self.llm.ainvoke(messages)
            content = response.content.strip().upper()
            return "YES" in content
        except Exception:
            return False

    async def chat_stream(self, session_id: str, user_input: str, system_prompt: Optional[str] = None, enable_search_tool: bool = False) -> AsyncIterator[str]:
        """
        æµå¼èŠå¤©æ–¹æ³•
        
        Args:
            session_id: ä¼šè¯ID
            user_input: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            enable_search_tool: æ˜¯å¦å¯ç”¨æœç´¢å·¥å…·
            
        Yields:
            æµå¼å“åº”ç‰‡æ®µ
        """
        # ç¡®ä¿æ™ºèƒ½ä½“å·²åˆå§‹åŒ–
        if not self._initialized:
            await self._async_init()

        # é»˜è®¤ä½¿ç”¨ç»Ÿä¸€é…ç½®çš„system_prompt
        if system_prompt is None:
            system_prompt = settings.system_prompt

        # æ›´æ–°ä¼šè¯è®°å¿†
        if session_id not in self.session_memory:
            self.session_memory[session_id] = []

        self.session_memory[session_id].append({
            "role": "user",
            "content": user_input,
            "timestamp": time.time()
        })

        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = {
            "input": user_input,
            "messages": [HumanMessage(content=user_input)],
            "system_prompt": system_prompt
        }

        # é…ç½®å‚æ•°
        config = {
            "configurable": {
                "thread_id": session_id
            }
        }

        # é€‰æ‹©Agent
        agent_to_use = self.agent_search if (enable_search_tool and self.agent_search) else self.agent_basic
        
        # å°è¯•ä¿®å‰ªå†å²è®°å½•ä»¥é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        try:
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒ LangGraph çŠ¶æ€ç®¡ç†
            if hasattr(agent_to_use, "aget_state") and hasattr(agent_to_use, "aupdate_state"):
                current_state = await agent_to_use.aget_state(config)
                if current_state and current_state.values and "messages" in current_state.values:
                    messages = current_state.values["messages"]
                    total_chars = 0
                    for m in messages:
                        if hasattr(m, 'content') and isinstance(m.content, str):
                            total_chars += len(m.content)
                    
                    if total_chars > settings.max_history_chars:
                        chars_to_remove = total_chars - settings.max_history_chars
                        removed_chars = 0
                        messages_to_remove = []
                        
                        for m in messages:
                            # ä¿ç•™ SystemMessage
                            if isinstance(m, SystemMessage):
                                continue
                            
                            # ä»…ç§»é™¤å…·æœ‰ ID çš„æ¶ˆæ¯
                            if hasattr(m, 'id') and m.id:
                                content_len = len(m.content) if (hasattr(m, 'content') and isinstance(m.content, str)) else 0
                                messages_to_remove.append(RemoveMessage(id=m.id))
                                removed_chars += content_len
                                
                                if removed_chars >= chars_to_remove:
                                    break
                        
                        if messages_to_remove:
                            print(f"[Agent] Trimming history: removing {len(messages_to_remove)} messages to save {removed_chars} chars.")
                            await agent_to_use.aupdate_state(config, {"messages": messages_to_remove})
        except Exception as e:
            print(f"[Agent] Warning: Failed to trim history: {e}")

        full_response = ""
        
        try:
            # ä½¿ç”¨ astream_events è·å–æµå¼è¾“å‡º
            # version='v1' å…¼å®¹æ€§æ›´å¥½
            async for event in agent_to_use.astream_events(input_data, config=config, version="v1"):
                kind = event["event"]
                # print(f"[Debug] Agent event: {kind}", flush=True)
                
                # è¿‡æ»¤å¹¶æå–æ–‡æœ¬ç”Ÿæˆå†…å®¹
                if kind == "on_chat_model_stream":
                    chunk = event["data"]["chunk"]
                    print(f"[Debug] Chunk content: {repr(chunk.content)}", flush=True)
                    if hasattr(chunk, "content"):
                        content = chunk.content
                        if content:
                            full_response += content
                            yield content
                
                # å¯é€‰: å¤„ç†å·¥å…·è°ƒç”¨äº‹ä»¶
                if kind == "on_tool_start":
                     # yield f"\n[Thinking: Calling tool {event['name']}...]\n"
                     yield "\nğŸ” **æ­£åœ¨è”ç½‘æœç´¢ç›¸å…³ä¿¡æ¯...**\n"
                
                if kind == "on_tool_end":
                     # yield f"\n[Thinking: Tool execution completed]\n"
                     yield "\nâœ… **æœç´¢å®Œæˆï¼Œæ­£åœ¨æ•´ç†å›ç­”...**\n"

        except asyncio.CancelledError:
            # å¤„ç†æµè¢«å–æ¶ˆçš„æƒ…å†µï¼ˆå¦‚å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼‰
            full_response += "\n[Interrupted]"
            print(f"[Agent] Stream cancelled for session {session_id}")
            raise

        except Exception as e:
            error_msg = f"Error during streaming: {str(e)}"
            print(error_msg)
            full_response += f"\n[Error: {str(e)}]"
            yield f"\n[System Error: {str(e)}]"

        finally:
            # æ— è®ºæˆåŠŸã€å¤±è´¥è¿˜æ˜¯ä¸­æ–­ï¼Œéƒ½ä¿å­˜ç”Ÿæˆçš„å›å¤åˆ°è®°å¿†ä¸­
            if full_response.strip():
                self.session_memory[session_id].append({
                    "role": "assistant",
                    "content": full_response,
                    "timestamp": time.time()
                })

                # ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶
                self._save_session(session_id)


    def _save_session(self, session_id: str): 
        """ 
        ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶ 
        """ 
        try: 
            file_path = os.path.join(self.memory_dir, f"session_{session_id}.json") 
 
            session_data = { 
                "session_id": session_id, 
                "memory": self.session_memory.get(session_id, []), 
                "save_time": time.time(), 
                "save_date": time.strftime("%Y-%m-%d %H:%M:%S") 
            } 
 
            with open(file_path, 'w', encoding='utf-8') as f: 
                json.dump(session_data, f, ensure_ascii=False, indent=2) 
 
        except Exception: 
            pass 
 
    def clear_session(self, session_id: str): 
        """ 
        æ¸…ç†ä¼šè¯è®°å¿† 
        """ 
        if session_id in self.session_memory: 
            del self.session_memory[session_id] 
 
        file_path = os.path.join(self.memory_dir, f"session_{session_id}.json") 
        if os.path.exists(file_path): 
            os.remove(file_path) 
 
    def get_available_tools(self) -> List[str]: 
        """ 
        è·å–å¯ç”¨å·¥å…·åˆ—è¡¨ 
        """ 
        return [tool.name for tool in self.tools] 
 
    def get_session_history(self, session_id: str) -> List[Dict]: 
        """ 
        è·å–ä¼šè¯å†å² 
        """ 
        return self.session_memory.get(session_id, []) 
